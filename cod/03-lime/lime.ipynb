{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a69f9a5d",
   "metadata": {},
   "source": [
    "## Set up local environment\n",
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ece68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.linear_model import LinearRegression, Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d2623e",
   "metadata": {},
   "source": [
    "Plot silly graph for tabular example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a47755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Black-box model\n",
    "def f(x):\n",
    "    return x**2 - (x**3) / 9\n",
    "f = np.vectorize(f)\n",
    "\n",
    "# Point of interest\n",
    "x0 = 4\n",
    "sx = 2\n",
    "\n",
    "# Sampler from normal distribution\n",
    "sampler = stats.norm(loc=x0, scale=sx)\n",
    "\n",
    "# Perturbed data set\n",
    "x = sampler.rvs(30, random_state=42)\n",
    "d = pd.DataFrame({'x':x, 'f':f(x)})\n",
    "w = np.exp(np.power(d['x'] - x0, 2) / -2) # Exponential weights\n",
    "d['w'] = w\n",
    "\n",
    "# Fit local model\n",
    "m = LinearRegression()\n",
    "m.fit(\n",
    "    X=d[['x']],\n",
    "    y=d['f'],\n",
    "    sample_weight=d['w']\n",
    ")\n",
    "\n",
    "# Surrogate model\n",
    "def g(x):\n",
    "    return m.intercept_ + m.coef_.item(0) * x\n",
    "g = np.vectorize(g)\n",
    "\n",
    "# Define range\n",
    "x = np.arange(0, 10, 0.01)\n",
    "\n",
    "# Plot f, d and g\n",
    "plt.plot(x, f(x), label='f')\n",
    "plt.scatter(d['x'], d['f'], color='C1', alpha=d['w'])\n",
    "plt.plot(x, g(x), color='C1', label='g')\n",
    "\n",
    "# Aesthetics\n",
    "plt.axvline(x0, ls='--', color='C0')\n",
    "plt.xlim(2, 7)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.legend()\n",
    "\n",
    "# Show & save\n",
    "plt.savefig('../../fig/tabular.png', bbox_inches='tight', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1575b821",
   "metadata": {},
   "source": [
    "Read comments as data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5476051f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../../dat/scored_comments.csv')\n",
    "\n",
    "# Drop NAs\n",
    "df = df.dropna(how='any').reset_index(drop=True)\n",
    "\n",
    "# Count\n",
    "print(f'Number of comments:{len(df)}')\n",
    "print(f\"Within {df['date'].min()} and {df['date'].max()}\")\n",
    "\n",
    "# Visualize\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1932ee43",
   "metadata": {},
   "source": [
    "Count how many comments have _some_ negative tone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d1f044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare negative tone indicator\n",
    "df['neg'] = (df['score'] > 0).astype(int)\n",
    "\n",
    "# Summarize\n",
    "neg = df['neg'].mean()\n",
    "print(f\"{round(neg * 100, 1)}% of comments have some degree of negativity ({df['neg'].sum()}).\")\n",
    "\n",
    "# Keep only negative comments\n",
    "df = df[df['neg'] > 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc9c122",
   "metadata": {},
   "source": [
    "Short list of negative comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60b41a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three random comments\n",
    "t = df[['comment','score']].sample(6, random_state=42)\n",
    "\n",
    "# To latex\n",
    "# print(t.to_latex(index=False))\n",
    "\n",
    "for comment in t['comment']:\n",
    "    print(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c719e49e",
   "metadata": {},
   "source": [
    "Initialize VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0854db5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3149dfa1",
   "metadata": {},
   "source": [
    "## Example for a single comment\n",
    "Extract a single comment from the entire comment section and manually repeat the process carried out by LIME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe387eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract one comment from `df`\n",
    "c = df.iloc[1]\n",
    "comment = c['comment']\n",
    "print('Selected comment:', comment, sep='\\n  ')\n",
    "\n",
    "# Comment into list\n",
    "words = [word for word in comment.split(' ')]\n",
    "print('Comment as list of words:', words, sep='\\n  ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045fbd60",
   "metadata": {},
   "source": [
    "Randomly take out words from comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f7a5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize bernoulli distribution\n",
    "B = stats.bernoulli(p=0.8)\n",
    "\n",
    "# Select words based on Bernoulli random variable (N times)\n",
    "d = []\n",
    "for i in range(100):\n",
    "    d.append(list(B.rvs(len(words), random_state=42+i)))\n",
    "    \n",
    "# Modifications to data frame\n",
    "t = pd.DataFrame(data=d, columns=words)\n",
    "\n",
    "# Remove duplicates\n",
    "t = t.drop_duplicates()\n",
    "\n",
    "# Set weight based on closeness to original text\n",
    "t['weight'] = t.sum(axis=1) / len(words)\n",
    "\n",
    "# Drop entries where closeness is 1\n",
    "t = t[t['weight'] < 1].reset_index(drop=True)\n",
    "\n",
    "# Get original score\n",
    "t['score0'] = c['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17beffde",
   "metadata": {},
   "source": [
    "Score new observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1943e4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty list\n",
    "scores = []\n",
    "\n",
    "for i in t.index.values:\n",
    "    # Extract modified version of text\n",
    "    mod = t.iloc[i, :-1]\n",
    "    mod = ' '.join(list(mod[mod > 0].index.values))\n",
    "\n",
    "    # Append score to list\n",
    "    scores.append(m.polarity_scores(mod)['neg'])\n",
    "\n",
    "# Add new scores to `t`\n",
    "t['score1'] = scores\n",
    "\n",
    "# Visualize\n",
    "t.head()\n",
    "\n",
    "# To latex\n",
    "# print(t.head().to_latex(float_format='%.3f', index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65e582d",
   "metadata": {},
   "source": [
    "Fit lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc55225",
   "metadata": {},
   "outputs": [],
   "source": [
    "penalties = np.arange(0.01, 1 + 0.01, 0.01)\n",
    "coefs = []\n",
    "for penalty in penalties:\n",
    "    # Fit lasso\n",
    "    m = Lasso(alpha=penalty, fit_intercept=False)\n",
    "    m.fit(X=t[['score1']], y=t.loc[:, 'How':'up?'], sample_weight=t['weight'])\n",
    "\n",
    "    # Append coefs\n",
    "    coefs.append(list(np.transpose(m.coef_)[0]))\n",
    "\n",
    "# To df\n",
    "s = pd.DataFrame(data=coefs, columns=t.columns[:-3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560c521c",
   "metadata": {},
   "source": [
    "Plot convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7386d5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in s.columns:\n",
    "    plt.plot(penalties, s[col].values, label=col)\n",
    "\n",
    "# Cutoff\n",
    "cutoff = 0.11\n",
    "plt.axvline(x=cutoff, ls='--')\n",
    "\n",
    "# Ticks and labels\n",
    "plt.xticks(penalties, rotation=45)\n",
    "plt.xlim(0.01, 0.15)\n",
    "plt.xlabel('Penalty (lambda)')\n",
    "plt.ylabel('Estimate')\n",
    "plt.legend()\n",
    "\n",
    "# Show and save\n",
    "plt.savefig('../../fig/lasso.png', bbox_inches='tight', dpi=200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbd67c3",
   "metadata": {},
   "source": [
    "LIME explanation at data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6903da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-fit lassso with penalty=0.1\n",
    "m = Lasso(alpha=cutoff, fit_intercept=False)\n",
    "m.fit(X=t[['score1']], y=t.loc[:, 'How':'up?'], sample_weight=t['weight'])\n",
    "\n",
    "# Get fitted parameters\n",
    "res = pd.DataFrame({'Word':t.columns.values[:len(words)], 'Coef':m.coef_.flatten()})\n",
    "\n",
    "# Visualize\n",
    "res[res['Coef'] > 0].round(2)\n",
    "\n",
    "# To latex\n",
    "# print(res[res['Coef'] > 0].to_latex(index=False, float_format='%.2f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a38aa21",
   "metadata": {},
   "source": [
    "## General results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac3a705",
   "metadata": {},
   "source": [
    "### TO-DO:\n",
    "# Word cloud\n",
    "# Generalize on popular comments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
