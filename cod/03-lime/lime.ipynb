{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a69f9a5d",
   "metadata": {},
   "source": [
    "## Set up local environment\n",
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ece68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d2623e",
   "metadata": {},
   "source": [
    "Plot silly graph for tabular example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a47755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Black-box model\n",
    "def f(x):\n",
    "    return x**2 - (x**3) / 9\n",
    "f = np.vectorize(f)\n",
    "\n",
    "# Point of interest\n",
    "x0 = 4\n",
    "sx = 2\n",
    "\n",
    "# Sampler from normal distribution\n",
    "sampler = stats.norm(loc=x0, scale=sx)\n",
    "\n",
    "# Perturbed data set\n",
    "x = sampler.rvs(30, random_state=42)\n",
    "d = pd.DataFrame({'x':x, 'f':f(x)})\n",
    "w = np.exp(np.power(d['x'] - x0, 2) / -2) # Exponential weights\n",
    "d['w'] = w\n",
    "\n",
    "# Fit local model\n",
    "m = LinearRegression()\n",
    "m.fit(\n",
    "    X=d[['x']],\n",
    "    y=d['f'],\n",
    "    sample_weight=d['w']\n",
    ")\n",
    "\n",
    "# Surrogate model\n",
    "def g(x):\n",
    "    return m.intercept_ + m.coef_.item(0) * x\n",
    "g = np.vectorize(g)\n",
    "\n",
    "# Define range\n",
    "x = np.arange(0, 10, 0.01)\n",
    "\n",
    "# Plot f, d and g\n",
    "plt.plot(x, f(x), label='f')\n",
    "plt.scatter(d['x'], d['f'], color='C1', alpha=d['w'])\n",
    "plt.plot(x, g(x), color='C1', label='g')\n",
    "\n",
    "# Aesthetics\n",
    "plt.axvline(x0, ls='--', color='C0')\n",
    "plt.xlim(2, 7)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.legend()\n",
    "\n",
    "# Show & save\n",
    "# plt.savefig('../../fig/tabular.png', bbox_inches='tight', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1575b821",
   "metadata": {},
   "source": [
    "Read comments as data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5476051f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../../dat/scored_comments.csv', encoding='utf-8')\n",
    "\n",
    "# Remove line skip strings\n",
    "df['comment'] = df['comment'].str.replace('\\n', '')\n",
    "\n",
    "# Drop NAs\n",
    "df = df.dropna(how='any').reset_index(drop=True)\n",
    "\n",
    "# Count\n",
    "print(f'Number of comments:{len(df)}')\n",
    "print(f\"Within {df['date'].min()} and {df['date'].max()}\")\n",
    "\n",
    "# Visualize\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1932ee43",
   "metadata": {},
   "source": [
    "Count how many comments have _some_ negative tone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d1f044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare negative tone indicator\n",
    "df['neg'] = (df['score'] > 0).astype(int)\n",
    "\n",
    "# Summarize\n",
    "neg = df['neg'].mean()\n",
    "print(f\"{round(neg * 100, 1)}% of comments have some degree of negativity ({df['neg'].sum()}).\")\n",
    "\n",
    "# Keep only negative comments\n",
    "df = df[df['neg'] > 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc9c122",
   "metadata": {},
   "source": [
    "Short list of negative comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60b41a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three random comments\n",
    "t = df[['comment','score']].sample(6, random_state=42)\n",
    "\n",
    "# To latex\n",
    "# print(t.to_latex(index=False))\n",
    "\n",
    "for comment in t['comment']:\n",
    "    print(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c719e49e",
   "metadata": {},
   "source": [
    "Initialize VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0854db5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vader = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3149dfa1",
   "metadata": {},
   "source": [
    "## Example for a single comment\n",
    "Extract a single comment from the entire comment section and manually repeat the process carried out by LIME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe387eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract one comment from `df`\n",
    "c = df.iloc[1]\n",
    "comment = c['comment']\n",
    "print('Selected comment:', comment, sep='\\n  ')\n",
    "\n",
    "# Comment into list\n",
    "words = [word for word in comment.split(' ')]\n",
    "print('Comment as list of words:', words, sep='\\n  ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045fbd60",
   "metadata": {},
   "source": [
    "Randomly take out words from comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f7a5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize bernoulli distribution\n",
    "B = stats.bernoulli(p=0.8)\n",
    "\n",
    "# Select words based on Bernoulli random variable (N times)\n",
    "d = []\n",
    "for i in range(100):\n",
    "    d.append(list(B.rvs(len(words), random_state=42+i)))\n",
    "    \n",
    "# Modifications to data frame\n",
    "t = pd.DataFrame(data=d, columns=words)\n",
    "\n",
    "# Remove duplicates\n",
    "t = t.drop_duplicates()\n",
    "\n",
    "# Set weight based on closeness to original text\n",
    "t['weight'] = t.sum(axis=1) / len(words)\n",
    "\n",
    "# Drop entries where closeness is 1\n",
    "t = t[t['weight'] < 1].reset_index(drop=True)\n",
    "\n",
    "# Get original score\n",
    "t['score0'] = c['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17beffde",
   "metadata": {},
   "source": [
    "Score new observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1943e4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty list\n",
    "scores = []\n",
    "\n",
    "for i in t.index.values:\n",
    "    # Extract modified version of text\n",
    "    mod = t.iloc[i, :-1]\n",
    "    mod = ' '.join(list(mod[mod > 0].index.values))\n",
    "\n",
    "    # Append score to list\n",
    "    scores.append(vader.polarity_scores(mod)['neg'])\n",
    "\n",
    "# Add new scores to `t`\n",
    "t['score1'] = scores\n",
    "\n",
    "# Visualize\n",
    "t.head()\n",
    "\n",
    "# To latex\n",
    "# print(t.head().to_latex(float_format='%.3f', index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65e582d",
   "metadata": {},
   "source": [
    "Fit lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc55225",
   "metadata": {},
   "outputs": [],
   "source": [
    "penalties = np.arange(0.01, 1 + 0.01, 0.01)\n",
    "coefs = []\n",
    "for penalty in penalties:\n",
    "    # Fit lasso\n",
    "    m = Lasso(alpha=penalty, fit_intercept=False)\n",
    "    m.fit(X=t[['score1']], y=t.loc[:, 'How':'up?'], sample_weight=t['weight'])\n",
    "\n",
    "    # Append coefs\n",
    "    coefs.append(list(np.transpose(m.coef_)[0]))\n",
    "\n",
    "# To df\n",
    "s = pd.DataFrame(data=coefs, columns=t.columns[:-3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560c521c",
   "metadata": {},
   "source": [
    "Plot convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7386d5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in s.columns:\n",
    "    plt.plot(penalties, s[col].values, label=col)\n",
    "\n",
    "# Cutoff\n",
    "cutoff = 0.11\n",
    "plt.axvline(x=cutoff, ls='--')\n",
    "\n",
    "# Ticks and labels\n",
    "plt.xticks(penalties, rotation=45)\n",
    "plt.xlim(0.01, 0.15)\n",
    "plt.xlabel('Penalty (lambda)')\n",
    "plt.ylabel('Estimate')\n",
    "plt.legend()\n",
    "\n",
    "# Show and save\n",
    "# plt.savefig('../../fig/lasso.png', bbox_inches='tight', dpi=200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbd67c3",
   "metadata": {},
   "source": [
    "LIME explanation at data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6903da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-fit lassso with penalty=0.1\n",
    "m = Lasso(alpha=cutoff, fit_intercept=False)\n",
    "m.fit(X=t[['score1']], y=t.loc[:, 'How':'up?'], sample_weight=t['weight'])\n",
    "\n",
    "# Get fitted parameters\n",
    "res = pd.DataFrame({'Word':t.columns.values[:len(words)], 'Coef':m.coef_.flatten()})\n",
    "\n",
    "# Visualize\n",
    "res[res['Coef'] > 0].round(2)\n",
    "\n",
    "# To latex\n",
    "# print(res[res['Coef'] > 0].to_latex(index=False, float_format='%.2f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a38aa21",
   "metadata": {},
   "source": [
    "## General results\n",
    "Split negative score into quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb98689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign quartiles\n",
    "df['score_quartile'] = pd.qcut(df['score'], q=4, labels=['Q1','Q2','Q3','Q4'])\n",
    "\n",
    "# Initialize stopwords\n",
    "sw = set(STOPWORDS)\n",
    "# sw.add('Battlefield')\n",
    "# sw.add('Dice')\n",
    "# sw.add(\"'s\")\n",
    "\n",
    "# Initialize figure\n",
    "fig, axs = plt.subplots(nrows=2, ncols=2)\n",
    "fig.set_figwidth(14)\n",
    "fig.set_figheight(8)\n",
    "\n",
    "# Possible titles\n",
    "d = {'Q1':'First', 'Q2':'Second', 'Q3':'Third', 'Q4':'Fourth'}\n",
    "\n",
    "# Wordcloud for each quartile\n",
    "for i, q in enumerate(['Q1','Q2','Q3','Q4']):\n",
    "    # Call ax from axs\n",
    "    ax = axs.flatten()[i]\n",
    "\n",
    "    # Text from comments in quartile\n",
    "    comments = df.loc[df['score_quartile'].eq(q), 'comment'].values\n",
    "    text = ' '.join([comment for comment in comments])\n",
    "\n",
    "    # Initialize wordcloud\n",
    "    wc = WordCloud(\n",
    "        max_words=20,\n",
    "        stopwords=sw,\n",
    "        background_color='black',\n",
    "        collocation_threshold=3,\n",
    "        colormap='Reds',\n",
    "        random_state=42\n",
    "    ).generate(text)\n",
    "    \n",
    "    # Aesthetics\n",
    "    ax.set_title(f'{d[q]} Quartile')\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Show wc\n",
    "    ax.imshow(wc)\n",
    "\n",
    "plt.savefig('../../fig/clouds.png', dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7f3849",
   "metadata": {},
   "source": [
    "_Bad Company_ analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60e353b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example comments\n",
    "comments = [\n",
    "    # Non-negative with high score (index 1113)\n",
    "    \"I still miss bad company 2\",\n",
    "    # Non-negative with low score (index 714)\n",
    "    \"Honestly you all gotta chill. I'm going to say it. Battlefield 2042 is a good game.\",\n",
    "    # Negative with high score (index 1079)\n",
    "    \"This game is a disgrace\",\n",
    "    # Negative with low score (index 1411)\n",
    "    \"The game has been delayed from October to November. Thanks again, Covid. What would be of our lives without you?\"\n",
    "]\n",
    "\n",
    "# Show in data\n",
    "df[df['comment'].isin(comments)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce7f8c2",
   "metadata": {},
   "source": [
    "Apply LIME to all four comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5835375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import function\n",
    "from lime import nlp\n",
    "\n",
    "# Make vader compatible with library\n",
    "def vader(x0):\n",
    "    return SentimentIntensityAnalyzer().polarity_scores(x0)['neg']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfebf63",
   "metadata": {},
   "source": [
    "### Case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803cf14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass comment and LIME it\n",
    "exp0 = nlp(x0=comments[0], blackbox=vader)\n",
    "exp0.perturb(nIter=300, p=0.2, random_state=42)\n",
    "exp0.fit(nFeatures=2)\n",
    "exp0.explanation.round(2)\n",
    "# print(exp0.explanation.to_latex(float_format='%.2f', index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a87a9a7",
   "metadata": {},
   "source": [
    "### Case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9237e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass comment and LIME it\n",
    "exp1 = nlp(x0=comments[1], blackbox=vader)\n",
    "exp1.perturb(nIter=300, p=0.2, random_state=42)\n",
    "exp1.fit(nFeatures=3)\n",
    "exp1.explanation.round(2)\n",
    "# print(exp1.explanation.to_latex(float_format='%.2f', index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b620c4d",
   "metadata": {},
   "source": [
    "### Case 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ddac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass comment and LIME it\n",
    "exp2 = nlp(x0=comments[2], blackbox=vader)\n",
    "exp2.perturb(nIter=300, p=0.2, random_state=42)\n",
    "exp2.fit(nFeatures=3)\n",
    "exp2.explanation.round(2)\n",
    "# print(exp2.explanation.to_latex(float_format='%.2f', index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275774c5",
   "metadata": {},
   "source": [
    "### Case 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d4b97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass comment and LIME it\n",
    "exp3 = nlp(x0=comments[3], blackbox=vader)\n",
    "exp3.perturb(nIter=300, p=0.2, random_state=42)\n",
    "exp3.fit(nFeatures=3)\n",
    "exp3.explanation.round(2)\n",
    "# print(exp3.explanation.to_latex(float_format='%.2f', index=False))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac34e6cab8f7bb13ceb54f7df84151ae0085d738607c2cafd728737a4c5d05eb"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
